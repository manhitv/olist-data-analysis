{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9451810-4af1-4899-9ab7-03a2bef73603",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy or anything else depending on industries). Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1307526b-fc91-4ed6-bd6f-3215e9c8c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from surprise import accuracy, Reader, Dataset\n",
    "from surprise import KNNBasic, SVD, NMF\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495be663-2a6a-4392-bdef-9b1955f8cfbb",
   "metadata": {},
   "source": [
    "## 1. Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47b37af-6867-4eb9-a732-5efb9274fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "olist = pd.read_csv('../data/processed/olist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d8ca2-8826-4aec-8bfb-64d6ba71c7c3",
   "metadata": {},
   "source": [
    "We will split data into new and repeat customers based on EDA (part 1) to treat them differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b04f2a6-cdaf-47c5-b5df-ad20ec57a4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repeat customers: 2807, new customers: 90589\n"
     ]
    }
   ],
   "source": [
    "num_of_order_per_customer = olist.groupby('customer_unique_id')['order_id'].nunique()\n",
    "repeat_customer_unique_id = num_of_order_per_customer[num_of_order_per_customer > 1].index.tolist()\n",
    "repeat_customers = olist.loc[olist.customer_unique_id.isin(repeat_customer_unique_id)]\n",
    "num_of_repeat_customers = len(repeat_customer_unique_id)\n",
    "total_num_of_customers = olist['customer_unique_id'].nunique()\n",
    "print(f'Number of repeat customers: {num_of_repeat_customers}, new customers: {total_num_of_customers - num_of_repeat_customers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed575760-a0a9-4447-9675-175980ff0995",
   "metadata": {},
   "source": [
    "For new customers: products will be recommended based on Popularity by Month (and/or by Location) or based on Highly Rated Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe9c322-695c-414b-a2fe-42fe2cbd3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************** \n",
      " Get popular products\n",
      "product_id\n",
      "aca2eb7d00ea1a7b8ebd4e68314663af    533\n",
      "99a4788cb24856965c36a24e339b6058    517\n",
      "422879e10f46682990de24d770e7f83d    507\n",
      "389d119b48cf3043d311335e499d9c6b    405\n",
      "368c6c730842d78016ad823897a372db    395\n",
      "Name: count, dtype: int64\n",
      "************************************************** \n",
      " Get popular products\n",
      "product_id\n",
      "0021a87d4997a48b6cef1665602be0f5    5.0\n",
      "001c5d71ac6ad696d22315953758fa04    5.0\n",
      "00066f42aeeb9f3007548bb9d3f33c38    5.0\n",
      "001b237c0e9bb435f2e54071129237e9    5.0\n",
      "fffdb2d0ec8d6a61f0a0a0db3f25b441    5.0\n",
      "Name: review_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Popular products\n",
    "print('*'*50, '\\n', 'Get popular products')\n",
    "print(olist['product_id'].value_counts().head())\n",
    "\n",
    "# Top rated products\n",
    "print('*'*50, '\\n', 'Get popular products')\n",
    "print(olist.groupby('product_id')['review_score'].mean().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789bf0e-5bc8-46f3-8e20-34091af092bb",
   "metadata": {},
   "source": [
    "We could see that we have many products with the same rating score, so that we might need more filters to get the best products. These filters will be generalized in the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e858845-f3ae-44a7-93d5-a93149d27a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************** \n",
      " Get top rated products in month=201711\n",
      "                                  avg_rating_score  count product_category\n",
      "product_id                                                                \n",
      "89b190a046022486c635022524a974a8               5.0     15  Furniture Decor\n",
      "47cd48073d67f91f09cb5ef9496c920b               5.0     10   Bed Bath Table\n",
      "1166bc797ddf5fb009c376d133f61204               5.0      9       Housewares\n",
      "846145e9b8d412bd1c9bb478a52ab4a0               5.0      9       Cool Stuff\n",
      "10b0226d162bdc55d60c0eabf68c7021               5.0      7   Sports Leisure\n",
      "************************************************** \n",
      " Get top rated products in Sao Paulo\n",
      "                                  avg_rating_score  count product_category\n",
      "product_id                                                                \n",
      "ebf9bc6cd600eadd681384e3116fda85               5.0     42   Bed Bath Table\n",
      "8d37ee446981d3790967d0268d6cfc81               5.0     26   Bed Bath Table\n",
      "5ddab10d5e0a23acb99acf56b62b3276               5.0     21       Housewares\n",
      "b9aad83bfbc546d2e4e7a7fa8e15bc9c               5.0     16       Housewares\n",
      "9e5f752e9e19cd6887063f004ee0da55               5.0     15  Furniture Decor\n"
     ]
    }
   ],
   "source": [
    "def get_top_rate_products(month=None, location=None):\n",
    "    if month:\n",
    "        df = olist.loc[olist.order_purchase_year_month == month]\n",
    "    elif location:\n",
    "        df = olist.loc[olist.customer_state == location]\n",
    "    else:\n",
    "        df = olist.copy()\n",
    "    agg_df = df.groupby('product_id').agg({'review_score': ['mean', 'count'], 'product_category_name_english': 'first'})\n",
    "    agg_df.columns = ['avg_rating_score', 'count', 'product_category']\n",
    "    output = agg_df.sort_values(by=['avg_rating_score', 'count'], ascending=[False, False]).head()\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Top rated products by month\n",
    "print('*'*50, '\\n', 'Get top rated products in month=201711')\n",
    "print(get_top_rate_products(month=201711))\n",
    "# Top rated products by location\n",
    "print('*'*50, '\\n', 'Get top rated products in Sao Paulo')\n",
    "print(get_top_rate_products(location='SP'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6968e74-0263-412a-9bdd-ff2157966e96",
   "metadata": {},
   "source": [
    "We will build a recommendation system for repeat customers in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b178db-4d1c-4aac-a8f5-606a0da14c65",
   "metadata": {},
   "source": [
    "## 2. Recommendation system approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfce1e6-86cd-415b-9007-8332c73ff98e",
   "metadata": {},
   "source": [
    "#### 2.1. Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98dae10-2a0e-4c2e-85dd-ce128afb40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: 5785 Number of customers: 1964\n",
      "Size of test data: 2419 Number of customers: 843\n"
     ]
    }
   ],
   "source": [
    "# Filter unique customer\n",
    "unique_customer_ids = repeat_customers['customer_unique_id'].unique()\n",
    "\n",
    "# Split unique customer ids into train and test\n",
    "train_customer_ids, test_customer_ids = train_test_split(unique_customer_ids, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Filter data for train and test sets based on customer ids\n",
    "train_data = repeat_customers[repeat_customers['customer_unique_id'].isin(train_customer_ids)]\n",
    "test_data = repeat_customers[repeat_customers['customer_unique_id'].isin(test_customer_ids)]\n",
    "\n",
    "# Print sizes of the resulting sets\n",
    "print('Size of train data:', len(train_data), 'Number of customers:', train_data.customer_unique_id.nunique())\n",
    "print('Size of test data:', len(test_data), 'Number of customers:', test_data.customer_unique_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0e00d-53a7-4611-8a18-868f57ac45f5",
   "metadata": {},
   "source": [
    "#### 2.2. Evaluation metrics\n",
    "- Using RMSE: compare predicted review score with actual `review score` to evaluate performance of current models. The lower RMSE, the better model.\n",
    "- Using top-K-accuracy to compare overall performance of all approaches. For simplicity, we choose K=5, i.e. when suggested product was bought by customer, we will count it as a True Positive. This metric are explainable and very close to actual business. The higher accuracy, the better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076ad67f-8ec0-4fff-a983-64510936853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_performance = {} # create new variable to store model metrics\n",
    "\n",
    "def evaluate_performance(predicted_review_scores=pd.DataFrame([]), top_products=[], k=5):\n",
    "    '''\n",
    "    predicted_review_scores dataframe will contain all predicted score of users for all products\n",
    "    '''\n",
    "    # For each user, we will suggest top K products with highest review score. If these scores are equal, we will choose it randomly.\n",
    "    tp = 0\n",
    "    for user_id in test_customer_ids:\n",
    "        if top_products:\n",
    "            suggested_products = top_products\n",
    "        else:\n",
    "            suggested_products = (predicted_review_scores\n",
    "                                  .loc[predicted_review_scores.customer_unique_id == user_id]\n",
    "                                  .sort_values(by='review_score', ascending=False)['product_id']\n",
    "                                  .head(k))\n",
    "        \n",
    "        bought_products = test_data.loc[test_data.customer_unique_id == user_id, 'product_id'].values\n",
    "        if any([i in bought_products for i in suggested_products]):\n",
    "            tp += 1\n",
    "    accuracy = round(tp / len(test_customer_ids), 3)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a719ab7-6306-4e49-a2fb-3d5a97b6dd87",
   "metadata": {},
   "source": [
    "#### 2.2. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ab67d-0ae5-4a7f-ad3e-b0fe1b2e7ca3",
   "metadata": {},
   "source": [
    "a. Rating prediction using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92aa537-0b11-4541-817a-70130df0ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "predicted_review_scores = test_data.copy()\n",
    "predicted_review_scores['product_id'] = np.random.choice(olist.product_id.unique(), size=len(test_data), replace=True)\n",
    "predicted_review_scores['review_score'] = train_data['review_score'].mean()\n",
    "\n",
    "overall_performance['Baseline: Mean Prediction'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce562e18-fda3-413a-8e28-0ca343336936",
   "metadata": {},
   "source": [
    "b. Top k popular products\n",
    "\n",
    "All users will be suggested by top 5 products as in the section 1 (for new customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7362586-3e93-490f-a36d-2fb14d42abca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03\n"
     ]
    }
   ],
   "source": [
    "top_popular_products = olist['product_id'].value_counts().head().index.tolist()\n",
    "\n",
    "overall_performance['Baseline: Top k popular products'] = evaluate_performance(top_products=top_popular_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a3179-4e64-45dc-952c-db70ade3034b",
   "metadata": {},
   "source": [
    "#### 2.3. Content-based Filtering Technique\n",
    "\n",
    "This technique bases on feature values of **products**. For each user, we try to suggest highest rating products by creating a ML model to learn from the input feature values to the output (`review_score`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e47279-6143-40ac-8578-466d5b138a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_features = ['product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', \n",
    "                    'product_height_cm', 'product_width_cm', 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c29777-1119-4578-963d-437104388fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input first\n",
    "all_products = repeat_customers[['product_id'] + product_features].drop_duplicates() # remove duplicates\n",
    "scaler = StandardScaler().fit(all_products[product_features])\n",
    "repeat_customers[product_features] = scaler.transform(repeat_customers[product_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25edf05-fd05-4c54-8b45-ac58867a900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get product suggestion\n",
    "user_product_suggestion_list = []\n",
    "for user_id in test_customer_ids:\n",
    "    df = test_data.loc[test_data.customer_unique_id == user_id, product_features + ['review_score']].drop_duplicates()\n",
    "    model = Ridge().fit(df[product_features], df['review_score'])\n",
    "    all_products['predicted_score'] = model.predict(all_products[product_features])\n",
    "    top_products = all_products.sort_values(by='predicted_score', ascending=False).head(5)\n",
    "    top_products.loc[:, 'customer_unique_id'] = [user_id for i in range(5)]\n",
    "    \n",
    "    user_product_suggestion_list.append(top_products[['customer_unique_id', 'product_id', 'predicted_score']]\n",
    "                                        .rename(columns={'predicted_score': 'review_score'}))\n",
    "\n",
    "predicted_review_scores = pd.concat(user_product_suggestion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bfdf208-41f7-43db-bcda-0412a361d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.001\n"
     ]
    }
   ],
   "source": [
    "overall_performance['Content-based Filtering'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013b9b7-2d1e-484f-a133-6cc8e9270af3",
   "metadata": {},
   "source": [
    "#### 2.4. Collaborative Filtering Technique: Memory-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd7aad-fd54-4afd-95b9-f7962bd82fe9",
   "metadata": {},
   "source": [
    "* We will create an utility matrix between users and products. This could be any relation between users and products such as click or not, watching time, rating... Our objective is to fill missing items. Note that these items generally very large compared to the available values.\n",
    "* We might consider to normalize (average subtraction) before combining with similarity matrix (average of k-nearest users). The similarity matrix is created from calculating *\"distances\"* between users-users or items-items, and this calculation plays an important roles in this approach. We will have several ways to calculate these kind of distances as follows.\n",
    "    - **User-user**: similarity is calculated between users --> \"People like you also like\", \"You might also like\"\n",
    "    - **Item-item**: similarity is calculated between items --> \"Users who bought this might also like this\" (similar items). Generally, it will be much faster than user-user, and secondly user profiles changes quickly and the entire system model has to be recomputed, whereas item's average ratings doesn't change that quickly, and this leads to more stable rating distributions in the model, so the model doesn't have to be rebuilt as often.\n",
    "    - **Similarity options**: cosine similarity (most common), Euclide distance, Pearson correlation or Jaccard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85af9262-e5b4-49f8-a5ae-f875be1136e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "util_matrix = repeat_customers[['customer_unique_id', 'product_id', 'review_score']]\n",
    "user_item_matrix = util_matrix.pivot_table(index='customer_unique_id', columns='product_id', values='review_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57bdde-4fd5-41b6-aeec-cfacc04c6641",
   "metadata": {},
   "source": [
    "*a. Item-based*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4251a2d-c5e6-4e41-9efe-15aaeb392395",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_matrix = user_item_matrix.apply(lambda col: col.fillna(col.mean()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d901e51b-18e7-4741-b14b-88d6c008d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ib_get_product_suggestion(item_corr_matrix):\n",
    "    # For each user, find top k similar products, based on their first purchase\n",
    "    user_product_suggestion_list = []\n",
    "    first_purchase = test_data.sort_values(by='order_purchase_timestamp', ascending=False).groupby('customer_unique_id')['product_id'].first()\n",
    "    \n",
    "    for user_id in test_customer_ids:\n",
    "        # Find first purchase product\n",
    "        first_product_id = first_purchase.loc[user_id]\n",
    "        \n",
    "        # Get top 5 similar products\n",
    "        selected_product_corr = item_corr_matrix[first_product_id].dropna()\n",
    "        top_products = pd.DataFrame(selected_product_corr.sort_values(ascending=False)[1:6]) # exclude the first one - the first purchase item\n",
    "        top_products.columns = ['corr']\n",
    "        \n",
    "        top_products = top_products.reset_index()\n",
    "        top_products.loc[:, 'customer_unique_id'] = [user_id for i in range(5)]\n",
    "    \n",
    "        user_product_suggestion_list.append(top_products)\n",
    "    \n",
    "    predicted_review_scores = (pd.concat(user_product_suggestion_list)\n",
    "                               .rename(columns={'corr': 'review_score'})\n",
    "                               [['customer_unique_id', 'product_id', 'review_score']])\n",
    "    \n",
    "    return predicted_review_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ddbde7a-0eb7-4eca-9e86-ccfac37a2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.079\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation\n",
    "item_corr_matrix = item_matrix.corr()\n",
    "predicted_review_scores = ib_get_product_suggestion(item_corr_matrix)\n",
    "overall_performance['Item-based CF: Pearson correlation'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a6739e7-9609-426e-928b-01ee8c7eca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.033\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "item_corr_matrix = cosine_similarity(item_matrix.T, item_matrix.T)\n",
    "item_corr_matrix = pd.DataFrame(item_corr_matrix, index=user_item_matrix.columns, columns=user_item_matrix.columns) # add index/columns\n",
    "\n",
    "predicted_review_scores = ib_get_product_suggestion(item_corr_matrix)\n",
    "overall_performance['Item-based CF: Cosine similarity'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a79944e-9c98-4bdc-8546-8f35775df9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Euclid distance\n",
    "item_corr_matrix = euclidean_distances(item_matrix.T, item_matrix.T)\n",
    "item_corr_matrix = pd.DataFrame(item_corr_matrix, index=user_item_matrix.columns, columns=user_item_matrix.columns) # add index/columns\n",
    "\n",
    "predicted_review_scores = ib_get_product_suggestion(item_corr_matrix)\n",
    "overall_performance['Item-based CF: Euclid distance'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6988c0e-ae88-4505-980a-529bd53a6635",
   "metadata": {},
   "source": [
    "*b. User-based*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ff6f350-db08-4ee2-b89a-74f2b9186198",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix = user_item_matrix.apply(lambda x: x.fillna(x.mean()), axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6029e943-9e8c-4afe-8ce6-dc9cff256bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ub_get_product_suggestion(user_similarity):\n",
    "    user_product_suggestion_list = []\n",
    "    \n",
    "    for user_id in test_customer_ids:\n",
    "        similar_users = user_similarity.loc[user_id].sort_values(ascending=True)[1:10] # average of 5 customers\n",
    "        \n",
    "        top_products = user_item_matrix.loc[similar_users.index].mean().sort_values(ascending=False).head(5) # top 5 products with highest rating\n",
    "        top_products = pd.DataFrame(top_products).rename(columns={0: 'review_score'}).reset_index()\n",
    "        top_products.loc[:, 'customer_unique_id'] = [user_id for i in range(5)]\n",
    "        \n",
    "        user_product_suggestion_list.append(top_products)\n",
    "    \n",
    "    predicted_review_scores = pd.concat(user_product_suggestion_list)\n",
    "\n",
    "    return predicted_review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32b822e3-1476-45fe-9b41-139e6c06338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.014\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation\n",
    "user_similarity = user_matrix.corr()\n",
    "\n",
    "predicted_review_scores = ub_get_product_suggestion(user_similarity)\n",
    "overall_performance['User-based CF: Pearson correlation'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74b2d6e-8c61-48f0-a1f0-a7b0d205df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "user_similarity = cosine_similarity(user_matrix.T, user_matrix.T)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index) # add index/columns\n",
    "\n",
    "predicted_review_scores = ub_get_product_suggestion(user_similarity)\n",
    "overall_performance['User-based CF: Cosine similarity'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33cbb158-293f-4fa8-93b3-7a2d90c07af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.024\n"
     ]
    }
   ],
   "source": [
    "# Euclid distance\n",
    "user_similarity = euclidean_distances(user_matrix.T, user_matrix.T)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index) # add index/columns\n",
    "\n",
    "predicted_review_scores = ub_get_product_suggestion(user_similarity)\n",
    "overall_performance['User-based CF: Euclid distance'] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d75ed5-7373-440b-ba92-2972975e5023",
   "metadata": {},
   "source": [
    "#### 2.4. Collaborative Filtering Technique: Model-based\n",
    "\n",
    "Basically, we compress user-item matrix into a low dimension matrix. We use techniques like SVD which is a low-rank factorization method, PCA which is used for dimensionaliry reduction etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ac6cf2-5d7c-4776-9142-9a893a8f0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "train_dataset = Dataset.load_from_df(train_data[['customer_unique_id', 'product_id', 'review_score']], reader)\n",
    "test_dataset = Dataset.load_from_df(test_data[['customer_unique_id', 'product_id', 'review_score']], reader)\n",
    "\n",
    "trainset = train_dataset.build_full_trainset()\n",
    "testset = test_dataset.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5ac842e-419e-46f9-a876-b4a8836c0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb_get_product_suggestion(model):\n",
    "    user_product_suggestion_list = []\n",
    "    \n",
    "    for user_id in test_customer_ids:\n",
    "        # Get top k recommendations for each user\n",
    "        user_predictions = model.test([(user_id, iid, 0) for iid in repeat_customers['product_id'].unique()])\n",
    "        top_pred = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "        \n",
    "        top_products = pd.DataFrame(\n",
    "            {'product_id': [pred.iid for pred in top_pred], \n",
    "             'review_score': [pred.est for pred in top_pred]}, \n",
    "            index=range(5))\n",
    "        top_products.loc[:, 'customer_unique_id'] = [user_id for i in range(5)]\n",
    "        \n",
    "        user_product_suggestion_list.append(top_products)\n",
    "    \n",
    "    predicted_review_scores = pd.concat(user_product_suggestion_list)\n",
    "\n",
    "    return predicted_review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1a133fb-5984-4bbb-bc09-cb1ca33b53a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************** \n",
      " Model-based CF - SVD\n",
      "RMSE: 1.4028\n",
      "Accuracy: 0.012\n",
      "************************************************** \n",
      " Model-based CF - NMF\n",
      "RMSE: 1.4032\n",
      "Accuracy: 0.0\n",
      "************************************************** \n",
      " Model-based CF - KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4032\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "models = {'Model-based CF - SVD': SVD(), 'Model-based CF - NMF': NMF(), 'Model-based CF - KNNBasic': KNNBasic()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print('*' * 50, '\\n', model_name)\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    rmse = round(accuracy.rmse(predictions), 3)\n",
    "\n",
    "    predicted_review_scores = mb_get_product_suggestion(model=model)\n",
    "    overall_performance[model_name] = evaluate_performance(predicted_review_scores=predicted_review_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce182f95-9923-4470-9d0e-2c31a3eed7f1",
   "metadata": {},
   "source": [
    "#### 2.5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb1203-f01c-4332-8564-801669d58555",
   "metadata": {},
   "source": [
    "Now we summarize all above results into a single one table. \n",
    "\n",
    "We could find that **Pearson correlation** provides better results than others despite it is quite computationally intensive. In addition, because the datasets are so small, the memory based filtering method shows significant efficiency compared to other methods, including model based filtering. With small datasets like this, it's clear that the basic method, suggest popular products, is showing a pretty solid baseline at **3%** for top 5 accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "006d3147-7568-4911-a7b6-24b3723fc856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline: Mean Prediction</th>\n",
       "      <th>Baseline: Top k popular products</th>\n",
       "      <th>Content-based Filtering</th>\n",
       "      <th>Item-based CF: Pearson correlation</th>\n",
       "      <th>Item-based CF: Cosine similarity</th>\n",
       "      <th>Item-based CF: Euclid distance</th>\n",
       "      <th>User-based CF: Pearson correlation</th>\n",
       "      <th>User-based CF: Cosine similarity</th>\n",
       "      <th>User-based CF: Euclid distance</th>\n",
       "      <th>Model-based CF - SVD</th>\n",
       "      <th>Model-based CF - NMF</th>\n",
       "      <th>Model-based CF - KNNBasic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Baseline: Mean Prediction  Baseline: Top k popular products  \\\n",
       "0                        0.0                              0.03   \n",
       "\n",
       "   Content-based Filtering  Item-based CF: Pearson correlation  \\\n",
       "0                    0.001                               0.079   \n",
       "\n",
       "   Item-based CF: Cosine similarity  Item-based CF: Euclid distance  \\\n",
       "0                             0.033                           0.001   \n",
       "\n",
       "   User-based CF: Pearson correlation  User-based CF: Cosine similarity  \\\n",
       "0                               0.014                             0.002   \n",
       "\n",
       "   User-based CF: Euclid distance  Model-based CF - SVD  Model-based CF - NMF  \\\n",
       "0                           0.024                 0.012                   0.0   \n",
       "\n",
       "   Model-based CF - KNNBasic  \n",
       "0                        0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(overall_performance, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c54ab15-4b4d-4c33-ae3b-670aa6ffdf16",
   "metadata": {},
   "source": [
    "## 4. Future works\n",
    "#### 4.1. Deep Learning-based models\n",
    "\n",
    "Nowadays, recommender systems have been improved with many approaches based on deep learning. \n",
    "The concept behind matrix factorization models is that the preferences of a user can be determined by a small number of hidden factors. And these are called as Embeddings. There are two types of architecture:\n",
    "\n",
    "- One using *dot product Embeddings* - we embedding user and item matrix separately, then use dot product to combine these information to create features\n",
    "- Another is called *concatenation Embeddings* - we concatenate user and item matrix after using Embedding to create features\n",
    "\n",
    "* Reference:\n",
    "    - https://d2l.ai/chapter_recommender-systems/movielens.html\n",
    "    - https://d2l.ai/chapter_recommender-systems/deepfm.html\n",
    "    - https://d2l.ai/chapter_recommender-systems/neumf.html\n",
    "    - https://github.com/recommenders-team/recommenders/blob/main/examples/06_benchmarks/movielens.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
